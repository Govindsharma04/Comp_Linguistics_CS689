{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8152523,"sourceType":"datasetVersion","datasetId":4821847},{"sourceId":8152619,"sourceType":"datasetVersion","datasetId":4821921},{"sourceId":8152881,"sourceType":"datasetVersion","datasetId":4822129},{"sourceId":8153199,"sourceType":"datasetVersion","datasetId":4822375},{"sourceId":8153251,"sourceType":"datasetVersion","datasetId":4822411},{"sourceId":8154495,"sourceType":"datasetVersion","datasetId":4823371},{"sourceId":8154605,"sourceType":"datasetVersion","datasetId":4823447}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Converting files to lists for easier calculations","metadata":{}},{"cell_type":"code","source":"#     hin_eng = []\n#     eng_hin = []\n#     hin_guj = []\n#     guj_hin = []\n\n# Reading each file and extracting the sentences in form of lists\nwith open('/kaggle/input/nllb-output/hindi_to_english.txt', 'r', encoding='utf-8') as file:\n    hin_eng = file.readlines()\nwith open('/kaggle/input/nllb-output/english_to_hindi.txt', 'r', encoding='utf-8') as file:\n    eng_hin = file.readlines()           \nwith open('/kaggle/input/nllb-output/hindi_to_gujarati.txt', 'r', encoding='utf-8') as file:\n    hin_guj = file.readlines()\nwith open('/kaggle/input/nllb-output/gujarati_to_hindi.txt', 'r', encoding='utf-8') as file:\n    guj_hin = file.readlines()\n\n\nprint(len(hin_eng),len(eng_hin),len(hin_guj),len(guj_hin))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:44:23.784162Z","iopub.execute_input":"2024-04-18T15:44:23.784583Z","iopub.status.idle":"2024-04-18T15:44:23.893702Z","shell.execute_reply.started":"2024-04-18T15:44:23.784548Z","shell.execute_reply":"2024-04-18T15:44:23.892887Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"1000 1000 1000 1000\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('/kaggle/input/gt-data/ground_truth_eng.txt', 'r', encoding='utf-8') as file:\n    gt_eng = file.readlines()\nwith open('/kaggle/input/gt-data/ground_truth_hin.txt', 'r', encoding='utf-8') as file:\n    gt_hin = file.readlines()           \nwith open('/kaggle/input/gt-data/ground_truth_guj.txt', 'r', encoding='utf-8') as file:\n    gt_guj = file.readlines()\nprint(len(gt_eng),len(gt_hin),len(gt_guj))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:44:26.259346Z","iopub.execute_input":"2024-04-18T15:44:26.259932Z","iopub.status.idle":"2024-04-18T15:44:26.305132Z","shell.execute_reply.started":"2024-04-18T15:44:26.259901Z","shell.execute_reply":"2024-04-18T15:44:26.304320Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"1000 1000 1000\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install rouge","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:44:29.557430Z","iopub.execute_input":"2024-04-18T15:44:29.557852Z","iopub.status.idle":"2024-04-18T15:44:45.631898Z","shell.execute_reply.started":"2024-04-18T15:44:29.557818Z","shell.execute_reply":"2024-04-18T15:44:45.630752Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting rouge\n  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\nInstalling collected packages: rouge\nSuccessfully installed rouge-1.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\nfrom rouge import Rouge \n\ndef calculate_scores(references, hypotheses):\n    # Calculate BLEU score\n    bleu_score = corpus_bleu([[ref] for ref in references], hypotheses)\n\n    # Initialize rouge scorer\n    rouge = Rouge()\n\n    # Calculate ROUGE scores\n    rouge_scores = rouge.get_scores(hypotheses, references, avg=True)\n\n    return bleu_score, rouge_scores","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:44:57.223603Z","iopub.execute_input":"2024-04-18T15:44:57.225001Z","iopub.status.idle":"2024-04-18T15:44:59.320021Z","shell.execute_reply.started":"2024-04-18T15:44:57.224959Z","shell.execute_reply":"2024-04-18T15:44:59.318861Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# BLEU and ROUGE scores of NLLB translations (considering random 1000 strings as GT)","metadata":{}},{"cell_type":"code","source":"BLEU_eng_hin, ROUGE_eng_hin = calculate_scores(gt_hin, eng_hin)\nprint(\"BLEU, ROUGE scores of eng_hin NLLB translation :- \\n\",BLEU_eng_hin, ROUGE_eng_hin)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:45:01.762289Z","iopub.execute_input":"2024-04-18T15:45:01.762824Z","iopub.status.idle":"2024-04-18T15:45:03.056147Z","shell.execute_reply.started":"2024-04-18T15:45:01.762776Z","shell.execute_reply":"2024-04-18T15:45:03.054908Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"BLEU, ROUGE scores of eng_hin NLLB translation :- \n 0.6238410931202366 {'rouge-1': {'r': 0.5657603916263654, 'p': 0.6132795262472982, 'f': 0.5832973119441415}, 'rouge-2': {'r': 0.3351294283402436, 'p': 0.3632610861098265, 'f': 0.34530847969231804}, 'rouge-l': {'r': 0.525339495267313, 'p': 0.569445220966497, 'f': 0.5416965483329408}}\n","output_type":"stream"}]},{"cell_type":"code","source":"BLEU_guj_hin, ROUGE_guj_hin = calculate_scores(gt_hin, guj_hin)\nprint(\"BLEU, ROUGE scores of guj_hin NLLB translation :- \\n\",BLEU_guj_hin, ROUGE_guj_hin)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:45:06.375344Z","iopub.execute_input":"2024-04-18T15:45:06.376381Z","iopub.status.idle":"2024-04-18T15:45:07.657693Z","shell.execute_reply.started":"2024-04-18T15:45:06.376346Z","shell.execute_reply":"2024-04-18T15:45:07.656613Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"BLEU, ROUGE scores of guj_hin NLLB translation :- \n 0.6258574729951193 {'rouge-1': {'r': 0.572571160143322, 'p': 0.6165391423827971, 'f': 0.5883882292049833}, 'rouge-2': {'r': 0.3546027496283749, 'p': 0.37947392048458745, 'f': 0.36315736624411193}, 'rouge-l': {'r': 0.5395456717461222, 'p': 0.5795444800723574, 'f': 0.5539642137849693}}\n","output_type":"stream"}]},{"cell_type":"code","source":"BLEU_hin_eng, ROUGE_hin_eng = calculate_scores(gt_eng, hin_eng)\nprint(\"BLEU, ROUGE scores of hin_eng NLLB translation :- \\n\",BLEU_hin_eng, ROUGE_hin_eng)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:45:11.653478Z","iopub.execute_input":"2024-04-18T15:45:11.653926Z","iopub.status.idle":"2024-04-18T15:45:12.960643Z","shell.execute_reply.started":"2024-04-18T15:45:11.653891Z","shell.execute_reply":"2024-04-18T15:45:12.959505Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"BLEU, ROUGE scores of hin_eng NLLB translation :- \n 0.6813263347414684 {'rouge-1': {'r': 0.6383501409431032, 'p': 0.6611282490166165, 'f': 0.6449393425960908}, 'rouge-2': {'r': 0.4009299064792981, 'p': 0.41447756152183707, 'f': 0.4041452719629579}, 'rouge-l': {'r': 0.6076346144304601, 'p': 0.6283106943908238, 'f': 0.6134810031648256}}\n","output_type":"stream"}]},{"cell_type":"code","source":"BLEU_hin_guj, ROUGE_hin_guj = calculate_scores(gt_guj, hin_guj)\nprint(\"BLEU, ROUGE scores of hin_guj by NLLB translation:- \\n\",BLEU_hin_guj, ROUGE_hin_guj)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T07:33:55.981920Z","iopub.execute_input":"2024-04-18T07:33:55.982401Z","iopub.status.idle":"2024-04-18T07:33:57.228850Z","shell.execute_reply.started":"2024-04-18T07:33:55.982360Z","shell.execute_reply":"2024-04-18T07:33:57.227730Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"BLEU, ROUGE scores of hin_guj by NLLB translation:- \n 0.5626953790995942 {'rouge-1': {'r': 0.4843260268717168, 'p': 0.5456115802841812, 'f': 0.5065547448886012}, 'rouge-2': {'r': 0.2558485170700022, 'p': 0.2898512307566872, 'f': 0.26777459699034273}, 'rouge-l': {'r': 0.4632681004233007, 'p': 0.5212619632216768, 'f': 0.48428068390018103}}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Reading each file and extracting the sentences in form of lists\nwith open('/kaggle/input/trans-data/hindi_to_english_indic.txt', 'r', encoding='utf-8') as file:\n    hin_eng_t = file.readlines()\nwith open('/kaggle/input/trans-data/indic_english_to_hindi.txt', 'r', encoding='utf-8') as file:\n    eng_hin_t = file.readlines()           \nwith open('/kaggle/input/trans-data/hindi_to_gujrati_indic.txt', 'r', encoding='utf-8') as file:\n    hin_guj_t = file.readlines()\nwith open('/kaggle/input/trans-data/gujrati_to_hindi_indic.txt', 'r', encoding='utf-8') as file:\n    guj_hin_t = file.readlines()\n\n\nprint(len(hin_eng_t),len(eng_hin_t),len(hin_guj_t),len(guj_hin_t))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T07:33:57.230169Z","iopub.execute_input":"2024-04-18T07:33:57.230498Z","iopub.status.idle":"2024-04-18T07:33:57.255287Z","shell.execute_reply.started":"2024-04-18T07:33:57.230468Z","shell.execute_reply":"2024-04-18T07:33:57.253909Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"1000 1000 1000 1000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# BLEU and ROUGE scores of INDIC_TRANS translations (considering random 1000 strings as GT)","metadata":{}},{"cell_type":"code","source":"BLEU_eng_hin, ROUGE_eng_hin = calculate_scores(gt_hin, eng_hin_t)\nprint(\"BLEU, ROUGE scores of eng_hin_t by Indic_trans :- \\n\",BLEU_eng_hin, ROUGE_eng_hin)\n\nBLEU_guj_hin, ROUGE_guj_hin = calculate_scores(gt_hin, guj_hin_t)\nprint(\"BLEU, ROUGE scores of guj_hin_t by Indic_trans :- \\n\",BLEU_guj_hin, ROUGE_guj_hin)\n\nBLEU_hin_eng, ROUGE_hin_eng = calculate_scores(gt_eng, hin_eng_t)\nprint(\"BLEU, ROUGE scores of hin_eng_t by Indic_trans :- \\n\",BLEU_hin_eng, ROUGE_hin_eng)\n\nBLEU_hin_guj, ROUGE_hin_guj = calculate_scores(gt_guj, hin_guj_t)\nprint(\"BLEU, ROUGE scores of hin_guj_t by Indic_trans :- \\n\",BLEU_hin_guj, ROUGE_hin_guj)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T07:33:58.687168Z","iopub.execute_input":"2024-04-18T07:33:58.687583Z","iopub.status.idle":"2024-04-18T07:34:04.343945Z","shell.execute_reply.started":"2024-04-18T07:33:58.687551Z","shell.execute_reply":"2024-04-18T07:34:04.342570Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"BLEU, ROUGE scores of eng_hin_t by Indic_trans :- \n 0.7010804828276995 {'rouge-1': {'r': 0.627134738039323, 'p': 0.6387824611720837, 'f': 0.6294308911401614}, 'rouge-2': {'r': 0.3981149341579366, 'p': 0.4054631230383377, 'f': 0.39957460718107796}, 'rouge-l': {'r': 0.5882417173275385, 'p': 0.5996213830614461, 'f': 0.5906624936967857}}\nBLEU, ROUGE scores of guj_hin_t by Indic_trans :- \n 0.8061704164359302 {'rouge-1': {'r': 0.7573710841280549, 'p': 0.7646905630919445, 'f': 0.7596724710926906}, 'rouge-2': {'r': 0.5758618498051863, 'p': 0.5817283389605588, 'f': 0.5776958698022132}, 'rouge-l': {'r': 0.7349128601101597, 'p': 0.7421497893103652, 'f': 0.7372219841513469}}\nBLEU, ROUGE scores of hin_eng_t by Indic_trans :- \n 0.7598250401809239 {'rouge-1': {'r': 0.6993702797101272, 'p': 0.6966866257390845, 'f': 0.694756588056114}, 'rouge-2': {'r': 0.4785918650672017, 'p': 0.475152317870466, 'f': 0.4741391281477733}, 'rouge-l': {'r': 0.6697503441464072, 'p': 0.6669611721679615, 'f': 0.6652824766102945}}\nBLEU, ROUGE scores of hin_guj_t by Indic_trans :- \n 0.6462430544805822 {'rouge-1': {'r': 0.5423321802612651, 'p': 0.5477299482483985, 'f': 0.5417461500907984}, 'rouge-2': {'r': 0.29381665115200695, 'p': 0.29433564479581525, 'f': 0.2922782052366178}, 'rouge-l': {'r': 0.5188512485892096, 'p': 0.524046102728228, 'f': 0.5183279681541167}}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# BLEU and ROUGE scores of ChatGPT translations (considering random 50 strings from random 1000 stringsas GT)","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/gt-chatgpt-updated/sen_hi_50.txt', 'r', encoding='utf-8') as file:\n    gt_hin_gpt = file.readlines()           \nwith open('/kaggle/input/gt-chatgpt-updated/sen_en_50.txt', 'r', encoding='utf-8') as file:\n    gt_eng_gpt = file.readlines()\nwith open('/kaggle/input/gt-chatgpt-updated/sen_gu_50.txt', 'r', encoding='utf-8') as file:\n    gt_guj_gpt = file.readlines()\n\n\nprint(len(gt_hin_gpt),len(gt_eng_gpt),len(gt_guj_gpt))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:52:45.464937Z","iopub.execute_input":"2024-04-18T09:52:45.465304Z","iopub.status.idle":"2024-04-18T09:52:45.473656Z","shell.execute_reply.started":"2024-04-18T09:52:45.465278Z","shell.execute_reply":"2024-04-18T09:52:45.472817Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"50 50 50\n","output_type":"stream"}]},{"cell_type":"code","source":"# Reading each file and extracting the sentences in form of lists\nwith open('/kaggle/input/chatgpt-transl/chatgpt_hi_to_en_50.txt', 'r', encoding='utf-8') as file:\n    hin_eng_gpt = file.readlines()\nwith open('/kaggle/input/chatgpt-transl/chatgpt_en_to_hi_50.txt', 'r', encoding='utf-8') as file:\n    eng_hin_gpt = file.readlines()           \nwith open('/kaggle/input/chatgpt-transl/chatgpt_hi_to_gu_50.txt', 'r', encoding='utf-8') as file:\n    hin_guj_gpt = file.readlines()\nwith open('/kaggle/input/chatgpt-transl/chatgpt_gu_to_hi_50.txt', 'r', encoding='utf-8') as file:\n    guj_hin_gpt = file.readlines()\n\n\nprint(len(hin_eng_gpt),len(eng_hin_gpt),len(hin_guj_gpt),len(guj_hin_gpt))","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:52:46.449008Z","iopub.execute_input":"2024-04-18T09:52:46.449395Z","iopub.status.idle":"2024-04-18T09:52:46.460108Z","shell.execute_reply.started":"2024-04-18T09:52:46.449365Z","shell.execute_reply":"2024-04-18T09:52:46.459166Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"50 50 50 50\n","output_type":"stream"}]},{"cell_type":"code","source":"BLEU_eng_hin, ROUGE_eng_hin = calculate_scores(gt_hin_gpt, eng_hin_gpt)\nprint(\"BLEU, ROUGE scores of eng_hin_gpt by ChatGPT Translations :- \\n\",BLEU_eng_hin, ROUGE_eng_hin)\n\nBLEU_guj_hin, ROUGE_guj_hin = calculate_scores(gt_hin_gpt, guj_hin_gpt)\nprint(\"BLEU, ROUGE scores of guj_hin_gpt by ChatGPT Translations :- \\n\",BLEU_guj_hin, ROUGE_guj_hin)\n\nBLEU_hin_eng, ROUGE_hin_eng = calculate_scores(gt_eng_gpt, hin_eng_gpt)\nprint(\"BLEU, ROUGE scores of hin_eng_gpt by ChatGPT Translations :- \\n\",BLEU_hin_eng, ROUGE_hin_eng)\n\nBLEU_hin_guj, ROUGE_hin_guj = calculate_scores(gt_guj_gpt, hin_guj_gpt)\nprint(\"BLEU, ROUGE scores of hin_guj_gpt by ChatGPT Translations :- \\n\",BLEU_hin_guj, ROUGE_hin_guj)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:52:47.293471Z","iopub.execute_input":"2024-04-18T09:52:47.294253Z","iopub.status.idle":"2024-04-18T09:52:47.510143Z","shell.execute_reply.started":"2024-04-18T09:52:47.294218Z","shell.execute_reply":"2024-04-18T09:52:47.509143Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"BLEU, ROUGE scores of eng_hin_gpt by ChatGPT Translations :- \n 0.6630466431047677 {'rouge-1': {'r': 0.5706433533570306, 'p': 0.5828101360757223, 'f': 0.5745591481047007}, 'rouge-2': {'r': 0.34889030629560985, 'p': 0.3590728051465116, 'f': 0.35265905021169763}, 'rouge-l': {'r': 0.5401872670235099, 'p': 0.5528763549821673, 'f': 0.5444856760191755}}\nBLEU, ROUGE scores of guj_hin_gpt by ChatGPT Translations :- \n 0.025834089332164044 {'rouge-1': {'r': 0.014166666666666668, 'p': 0.013883699633699634, 'f': 0.013975536304606809}, 'rouge-2': {'r': 0.006608187134502924, 'p': 0.006513157894736842, 'f': 0.006548262349070297}, 'rouge-l': {'r': 0.014166666666666668, 'p': 0.013883699633699634, 'f': 0.013975536304606809}}\nBLEU, ROUGE scores of hin_eng_gpt by ChatGPT Translations :- \n 0.6751911448954857 {'rouge-1': {'r': 0.5929007763194464, 'p': 0.5888789765159733, 'f': 0.5883066874234874}, 'rouge-2': {'r': 0.36669953931683674, 'p': 0.36354527279618787, 'f': 0.3633212416041245}, 'rouge-l': {'r': 0.5629984056721908, 'p': 0.5590522807659031, 'f': 0.5585905186099556}}\nBLEU, ROUGE scores of hin_guj_gpt by ChatGPT Translations :- \n 0.2925198064113558 {'rouge-1': {'r': 0.19790493079758004, 'p': 0.2133937533580707, 'f': 0.20156766254698724}, 'rouge-2': {'r': 0.07831418346464114, 'p': 0.08300514613973695, 'f': 0.07991797034837173}, 'rouge-l': {'r': 0.18965034056023117, 'p': 0.20365349361781104, 'f': 0.19283606081538557}}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}