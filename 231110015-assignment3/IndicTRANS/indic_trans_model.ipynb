{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8145937,"sourceType":"datasetVersion","datasetId":4817020}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!git clone https://github.com/AI4Bharat/IndicTrans2.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-17T17:42:04.928881Z","iopub.execute_input":"2024-04-17T17:42:04.929518Z","iopub.status.idle":"2024-04-17T17:42:05.917139Z","shell.execute_reply.started":"2024-04-17T17:42:04.929484Z","shell.execute_reply":"2024-04-17T17:42:05.916040Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%%capture\n%cd /content/IndicTrans2/huggingface_interface","metadata":{"execution":{"iopub.status.busy":"2024-04-17T17:42:05.919056Z","iopub.execute_input":"2024-04-17T17:42:05.919365Z","iopub.status.idle":"2024-04-17T17:42:05.925900Z","shell.execute_reply.started":"2024-04-17T17:42:05.919338Z","shell.execute_reply":"2024-04-17T17:42:05.924870Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"%%capture\n!python3 -m pip install nltk sacremoses pandas regex mock transformers>=4.33.2 mosestokenizer\n!python3 -c \"import nltk; nltk.download('punkt')\"\n!python3 -m pip install bitsandbytes scipy accelerate datasets\n!python3 -m pip install sentencepiece\n\n!git clone https://github.com/VarunGumma/IndicTransTokenizer\n%cd IndicTransTokenizer\n!python3 -m pip install --editable ./\n%cd ..","metadata":{"execution":{"iopub.status.busy":"2024-04-17T17:42:06.225957Z","iopub.execute_input":"2024-04-17T17:42:06.226600Z","iopub.status.idle":"2024-04-17T17:43:08.860199Z","shell.execute_reply.started":"2024-04-17T17:42:06.226569Z","shell.execute_reply":"2024-04-17T17:43:08.858862Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Read and Write Functions","metadata":{}},{"cell_type":"code","source":"# Defining Function for writing in files (we will use to convert lists to .txt files)\ndef write_files(file_path, lst):\n    with open(file_path, 'w', encoding='utf-8') as file:\n        for item in lst:\n            file.write(\"%s\\n\" % item)\n\n# Defining Function which will append eachsentence as a string in the list of string \nhindi_sentences = []\nenglish_sentences = []\ngujarati_sentences = []\n\n    # Reading each file and extracting the sentences in form of lists\nwith open('/kaggle/input/datasetsg/ground_truth_hin.txt', 'r', encoding='utf-8') as file:\n    hindi_sentences = file.readlines()\nwith open('/kaggle/input/datasetsg/ground_truth_eng.txt', 'r', encoding='utf-8') as file:\n    english_sentences = file.readlines()           \nwith open('/kaggle/input/datasetsg/ground_truth_guj.txt', 'r', encoding='utf-8') as file:\n    gujrati_sentences = file.readlines()\n# file_paths = (\"/kaggle/input/datasetsg/ground_truth_hin.txt\", \"/kaggle/input/datasetsg/ground_truth_eng.txt\", \"/kaggle/input/datasetsg/ground_truth_guj.txt\")\n# hindi_sentences_1k, english_sentences_1k, gujarati_sentences_1k = read_files(file_paths)\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-17T20:11:59.340991Z","iopub.execute_input":"2024-04-17T20:11:59.341980Z","iopub.status.idle":"2024-04-17T20:11:59.388502Z","shell.execute_reply.started":"2024-04-17T20:11:59.341943Z","shell.execute_reply":"2024-04-17T20:11:59.387580Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig\nfrom IndicTransTokenizer import IndicProcessor, IndicTransTokenizer\n\nBATCH_SIZE = 4\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nquantization = None","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:12:00.938016Z","iopub.execute_input":"2024-04-17T20:12:00.939106Z","iopub.status.idle":"2024-04-17T20:12:00.944626Z","shell.execute_reply.started":"2024-04-17T20:12:00.939059Z","shell.execute_reply":"2024-04-17T20:12:00.943527Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def initialize_model_and_tokenizer(ckpt_dir, direction, quantization):\n    if quantization == \"4-bit\":\n        qconfig = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_use_double_quant=True,\n            bnb_4bit_compute_dtype=torch.bfloat16,\n        )\n    elif quantization == \"8-bit\":\n        qconfig = BitsAndBytesConfig(\n            load_in_8bit=True,\n            bnb_8bit_use_double_quant=True,\n            bnb_8bit_compute_dtype=torch.bfloat16,\n        )\n    else:\n        qconfig = None\n\n    tokenizer = IndicTransTokenizer(direction=direction)\n    model = AutoModelForSeq2SeqLM.from_pretrained(\n        ckpt_dir,\n        trust_remote_code=True,\n        low_cpu_mem_usage=True,\n        quantization_config=qconfig,\n    )\n\n    if qconfig == None:\n        model = model.to(DEVICE)\n        if DEVICE == \"cuda\":\n            model.half()\n\n    model.eval()\n\n    return tokenizer, model\n\n\ndef batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer, ip):\n    translations = []\n    for i in range(0, len(input_sentences), BATCH_SIZE):\n        batch = input_sentences[i : i + BATCH_SIZE]\n\n        # Preprocess the batch and extract entity mappings\n        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n\n        # Tokenize the batch and generate input encodings\n        inputs = tokenizer(\n            batch,\n            src=True,\n            truncation=True,\n            padding=\"longest\",\n            return_tensors=\"pt\",\n            return_attention_mask=True,\n        ).to(DEVICE)\n\n        # Generate translations using the model\n        with torch.no_grad():\n            generated_tokens = model.generate(\n                **inputs,\n                use_cache=True,\n                min_length=0,\n                max_length=256,\n                num_beams=5,\n                num_return_sequences=1,\n            )\n\n        # Decode the generated tokens into text\n        generated_tokens = tokenizer.batch_decode(generated_tokens.detach().cpu().tolist(), src=False)\n\n        # Postprocess the translations, including entity replacement\n        translations += ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n\n        del inputs\n        torch.cuda.empty_cache()\n\n    return translations","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:12:03.338679Z","iopub.execute_input":"2024-04-17T20:12:03.339824Z","iopub.status.idle":"2024-04-17T20:12:03.351387Z","shell.execute_reply.started":"2024-04-17T20:12:03.339781Z","shell.execute_reply":"2024-04-17T20:12:03.350435Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"en_indic_ckpt_dir = \"ai4bharat/indictrans2-en-indic-1B\"  # ai4bharat/indictrans2-en-indic-dist-200M\nen_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir, \"en-indic\", quantization)\n\nip = IndicProcessor(inference=True)\n\nsrc_lang, tgt_lang = \"eng_Latn\", \"hin_Deva\"\nhi_translations = batch_translate(english_sentences, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip)\nwrite_files(\"english_to_hindi_indic.txt\", hi_translations)\n\n\n# delete the models to free the GPU memory\n# del en_indic_tokenizer, en_indic_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"en_indic_ckpt_dir = \"ai4bharat/indictrans2-indic-en-1B\"  # ai4bharat/indictrans2-en-indic-dist-200M\nen_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir, \"indic-en\", quantization)\n\nip = IndicProcessor(inference=True)\n\nsrc_lang, tgt_lang = \"hin_Deva\", \"eng_Latn\"\nen_translations = batch_translate(hindi_sentences, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip)\nprint(en_translations)\nwrite_files(\"hindi_to_english_indic.txt\", en_translations)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"en_indic_ckpt_dir = \"ai4bharat/indictrans2-indic-indic-1B\"  # ai4bharat/indictrans2-en-indic-dist-200M\nen_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir, \"indic-indic\", quantization)\n\nip = IndicProcessor(inference=True)\n\nsrc_lang, tgt_lang = \"hin_Deva\", \"guj_Gujr\"\nhi_to_guj_translations = batch_translate(hindi_sentences, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip)\nwrite_files(\"hindi_to_gujrati_indic.txt\", hi_to_guj_translations)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:15:26.253964Z","iopub.execute_input":"2024-04-17T20:15:26.254284Z","iopub.status.idle":"2024-04-17T20:18:43.267681Z","shell.execute_reply.started":"2024-04-17T20:15:26.254256Z","shell.execute_reply":"2024-04-17T20:18:43.266476Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"en_indic_ckpt_dir = \"ai4bharat/indictrans2-indic-indic-1B\"  # ai4bharat/indictrans2-en-indic-dist-200M\nen_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir, \"indic-indic\", quantization)\n\nip = IndicProcessor(inference=True)\n\nsrc_lang, tgt_lang = \"guj_Gujr\", \"hin_Deva\"\ngu_translations = batch_translate(hindi_sentences, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip)\nwrite_files(\"gujrati_to_hindi_indic.txt\", gu_translations)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:18:43.269058Z","iopub.execute_input":"2024-04-17T20:18:43.269488Z","iopub.status.idle":"2024-04-17T20:22:00.562987Z","shell.execute_reply.started":"2024-04-17T20:18:43.269446Z","shell.execute_reply":"2024-04-17T20:22:00.562134Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}