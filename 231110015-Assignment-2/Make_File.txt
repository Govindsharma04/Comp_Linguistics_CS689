# VariabdepsPYTHON=python3
REQUIREMENTS=transformers datasets sentencepiece seqeval

# Install requirements
deps:
pip install $(REQUIREMENTS)

# Download dataset
fetch_data:
	$(PYTHON) -c "from datasets import load_dataset; load_dataset('ai4bharat/naamapadam', 'hi')"

# Fine-tune model
fine_tune:
	$(PYTHON) -c "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification; config = AutoConfig.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels, finetuning_task='ner'); tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert'); model = AutoModelForTokenClassification.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels); trainer = Trainer(model=model, train_dataset=train_dataset, eval_dataset=eval_dataset, tokenizer=tokenizer, data_collator=data_collator, compute_metrics=compute_metrics, args=args); train_result = trainer.train(); model.save_pretrained('my_indicBERT'); tokenizer.save_pretrained('tokenizer_indicBERT')"

# Evaluate model
assess:
	$(PYTHON) -c "from transformers import AutoModelForTokenClassification; model = AutoModelForTokenClassification.from_pretrained('/kaggle/working/my_indicBERT'); predictions, labels, metrics = trainer.predict(test_dataset); print(metrics)"